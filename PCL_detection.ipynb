{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGdRONlKbJjMyn1aGUCjPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athishr88/PCLDetection/blob/main/PCL_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BzJrJllkLGEI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_main_lower = pd.read_csv(\"dontpatronizeme_pcl.tsv\",names=[\"par_ID\", \"art_ID\", \"Keyword\", \"country_code\", \"text\", \"Label\"], skiprows=4, sep='\\t')\n",
        "df_main_lower[\"text\"] = df_main_lower['text'].str.lower()\n",
        "df_main_lower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1CL8YGyKLLlN",
        "outputId": "cb77e6fc-000e-4c42-8638-0c274c5995ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       par_ID      art_ID     Keyword country_code  \\\n",
              "0           1  @@24942188    hopeless           ph   \n",
              "1           2  @@21968160     migrant           gh   \n",
              "2           3  @@16584954   immigrant           ie   \n",
              "3           4   @@7811231    disabled           nz   \n",
              "4           5   @@1494111     refugee           ca   \n",
              "...       ...         ...         ...          ...   \n",
              "10464   10465  @@14297363       women           lk   \n",
              "10465   10466  @@70091353  vulnerable           ph   \n",
              "10466   10467  @@20282330     in-need           ng   \n",
              "10467   10468  @@16753236    hopeless           in   \n",
              "10468   10469  @@16779383    homeless           ie   \n",
              "\n",
              "                                                    text  Label  \n",
              "0      we 're living in times of absolute insanity , ...      0  \n",
              "1      in libya today , there are countless number of...      0  \n",
              "2      white house press secretary sean spicer said t...      0  \n",
              "3      council customers only signs would be displaye...      0  \n",
              "4      \" just like we received migrants fleeing el sa...      0  \n",
              "...                                                  ...    ...  \n",
              "10464  sri lankan norms and culture inhibit women fro...      1  \n",
              "10465  he added that the afp will continue to bank on...      0  \n",
              "10466  \" she has one huge platform , and information ...      3  \n",
              "10467  \" anja ringgren loven i ca n't find a word to ...      4  \n",
              "10468  \" guinness world record of 540lbs of 7-layer m...      3  \n",
              "\n",
              "[10469 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d39783c7-f3d5-4787-acf6-b56c47e97a20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_ID</th>\n",
              "      <th>art_ID</th>\n",
              "      <th>Keyword</th>\n",
              "      <th>country_code</th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@@24942188</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>ph</td>\n",
              "      <td>we 're living in times of absolute insanity , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@@21968160</td>\n",
              "      <td>migrant</td>\n",
              "      <td>gh</td>\n",
              "      <td>in libya today , there are countless number of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@@16584954</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>white house press secretary sean spicer said t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>@@7811231</td>\n",
              "      <td>disabled</td>\n",
              "      <td>nz</td>\n",
              "      <td>council customers only signs would be displaye...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>@@1494111</td>\n",
              "      <td>refugee</td>\n",
              "      <td>ca</td>\n",
              "      <td>\" just like we received migrants fleeing el sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10464</th>\n",
              "      <td>10465</td>\n",
              "      <td>@@14297363</td>\n",
              "      <td>women</td>\n",
              "      <td>lk</td>\n",
              "      <td>sri lankan norms and culture inhibit women fro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10465</th>\n",
              "      <td>10466</td>\n",
              "      <td>@@70091353</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>ph</td>\n",
              "      <td>he added that the afp will continue to bank on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10466</th>\n",
              "      <td>10467</td>\n",
              "      <td>@@20282330</td>\n",
              "      <td>in-need</td>\n",
              "      <td>ng</td>\n",
              "      <td>\" she has one huge platform , and information ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10467</th>\n",
              "      <td>10468</td>\n",
              "      <td>@@16753236</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>in</td>\n",
              "      <td>\" anja ringgren loven i ca n't find a word to ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10468</th>\n",
              "      <td>10469</td>\n",
              "      <td>@@16779383</td>\n",
              "      <td>homeless</td>\n",
              "      <td>ie</td>\n",
              "      <td>\" guinness world record of 540lbs of 7-layer m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10469 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d39783c7-f3d5-4787-acf6-b56c47e97a20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d39783c7-f3d5-4787-acf6-b56c47e97a20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d39783c7-f3d5-4787-acf6-b56c47e97a20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_main_lower.iloc[10467].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "atNJEynarz_A",
        "outputId": "aca71d0e-12aa-4006-817d-f6766d03bd70"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" anja ringgren loven i ca n\\'t find a word to describe how i feel for you .... may god almighty keep blessing you and always give you strength and sound health to continue your good work ..... you gave hope to the hopeless ! ! ! ! have so much respect for you .. stay blessed my good fellow ... \" says one commenter on facebook . \" god bless you and your mission . glad to see hope ( and all the children ) growing up loved , well fed , happy , having fun , and going to school , \" says another .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_samples = df_main_lower.text[:5500]\n",
        "test_samples = df_main_lower.text[5500:]\n",
        "\n",
        "train_labels = df_main_lower.Label[:5500]\n",
        "test_labels = df_main_lower.Label[5500:]\n",
        "## Convert each label in the output to a unique integer\n",
        "classes = list(set(train_labels))\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmcQfnALLZq4",
        "outputId": "fb7fecca-b2e1-4f16-c06b-73488395e1d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter = Counter(test_labels)\n",
        "most_occur = Counter.most_common(6)\n",
        "most_occur"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTTgzVpxbdXp",
        "outputId": "04d7253b-cfcc-48d4-bd5a-37052a2c9524"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 4033), (1, 455), (3, 217), (4, 197), (2, 67)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an all token list\n",
        "\n",
        "all_tokens = [str(x) for x in train_samples]\n",
        "all_tokens = \" \".join(all_tokens)\n",
        "all_tokens = all_tokens.split(\" \")"
      ],
      "metadata": {
        "id": "Fu20kR4vOsua"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create our Text Vectorizer to index our vocabulary based on the train samples \n",
        "from keras.layers import TextVectorization\n",
        "import tensorflow as tf\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=10000, output_sequence_length=100)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(all_tokens).batch(128) ## Read batches of 128 samples\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "UfVhHHHfMHlM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Print out top five words in the vocab\n",
        "print(len(vectorizer.get_vocabulary())) ## We set max_tokens=10000\n",
        "vectorizer.get_vocabulary()[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eDnSjclMWJH",
        "outputId": "427242ba-34ca-41b4-f87e-9973240ec0ea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a map to get the unique list of the vocabulary\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "metadata": {
        "id": "Tzarf7-1Qb_2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_test = vectorizer(np.array([[s] for s in test_samples])).numpy()\n",
        "\n",
        "y_train = np.array(df_main_lower.Label, dtype=\"int\")\n",
        "y_test = np.array(test_labels, dtype=\"int\")"
      ],
      "metadata": {
        "id": "YSEV5AnZQcUI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efAMpKAydge5",
        "outputId": "6a88116f-84d4-485c-bf68-09c75bbced2c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Read the embeddings in the pretrained model (we are using the 100D version of GloVe)\n",
        "import os\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        if len(coefs) == 100:\n",
        "          embeddings_index[word] = coefs\n",
        "        \n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "id": "Eq2yIDXcSHnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d603f62-ce38-4ef9-c3a8-c5de981e0b69"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create \"embedding_matrix\" to index our vocabulary using the GloVe model \n",
        "num_tokens = len(voc) \n",
        "embedding_dim = 100 ## 100 dimensions\n",
        "hits = 0 ## number of words that were found in the pretrained model\n",
        "misses = 0 ## number of words that were missing in the pretrained model\n",
        "\n",
        "# Prepare embedding matrix for our word list\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-6zKxMYSIF5",
        "outputId": "8f3db2c9-fa0e-4f3c-d391-c5db0e54032c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 9751 words (249 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define our embedding layer for the training model \n",
        "## We load our embedding_matrix as the initializer and set trainable to False to avoid retraining this layer\n",
        "\n",
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "embedding_layer = Embedding(num_tokens, embedding_dim,\n",
        "                            embeddings_initializer= Constant(embedding_matrix), \n",
        "                            trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "Y7etVbaISeZe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight = {\n",
        "    0 : 1,\n",
        "    1 : 8,\n",
        "    2 : 40,\n",
        "    3 : 20,\n",
        "    4 : 30\n",
        "}"
      ],
      "metadata": {
        "id": "Pyw-tZzsb9WH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqhIzAwxoiGU",
        "outputId": "446d14a5-fbb8-4962-e6a1-5b7a10e04d4b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.17.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training different models\n",
        "from keras.layers import SimpleRNN, GRU, LSTM, Dropout\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras import layers, Input, Model\n",
        "from sklearn import metrics\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "\n",
        "x = layers.Bidirectional(layers.LSTM(200, return_sequences=True))(embedded_sequences)\n",
        "x = layers.Bidirectional(layers.LSTM(200))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = layers.Dense(50, activation=\"relu\")(x)\n",
        "preds = layers.Dense(len(classes), activation=\"softmax\")(x)\n",
        "model = Model(int_sequences_input, preds)\n",
        "\n",
        "model.summary()\n",
        "## Train the model \n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
        "model.fit(x_train, y_train, batch_size=128, class_weight=class_weight, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "_HZLNLGWTfQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55dc7d85-ca3d-4bcb-b85e-215083200e83"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, None, 400)        481600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 400)              961600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                20050     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,463,505\n",
            "Trainable params: 1,463,505\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "35/35 [==============================] - 16s 170ms/step - loss: 6.6258 - acc: 0.1884 - val_loss: 1.4880 - val_acc: 0.5809\n",
            "Epoch 2/20\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 6.3990 - acc: 0.4800 - val_loss: 1.2436 - val_acc: 0.6336\n",
            "Epoch 3/20\n",
            "35/35 [==============================] - 2s 66ms/step - loss: 6.3070 - acc: 0.4495 - val_loss: 1.0799 - val_acc: 0.6736\n",
            "Epoch 4/20\n",
            "35/35 [==============================] - 2s 66ms/step - loss: 6.2411 - acc: 0.5425 - val_loss: 1.3426 - val_acc: 0.5727\n",
            "Epoch 5/20\n",
            "35/35 [==============================] - 2s 66ms/step - loss: 6.1025 - acc: 0.5082 - val_loss: 1.5148 - val_acc: 0.4727\n",
            "Epoch 6/20\n",
            "35/35 [==============================] - 2s 66ms/step - loss: 5.8719 - acc: 0.5223 - val_loss: 1.1798 - val_acc: 0.5600\n",
            "Epoch 7/20\n",
            "35/35 [==============================] - 2s 67ms/step - loss: 5.6740 - acc: 0.4618 - val_loss: 1.0765 - val_acc: 0.5936\n",
            "Epoch 8/20\n",
            "35/35 [==============================] - 2s 66ms/step - loss: 5.4070 - acc: 0.4791 - val_loss: 1.2242 - val_acc: 0.4927\n",
            "Epoch 9/20\n",
            "35/35 [==============================] - 2s 67ms/step - loss: 5.1681 - acc: 0.4775 - val_loss: 1.1541 - val_acc: 0.5473\n",
            "Epoch 10/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 4.6741 - acc: 0.5570 - val_loss: 1.0352 - val_acc: 0.6036\n",
            "Epoch 11/20\n",
            "35/35 [==============================] - 2s 67ms/step - loss: 4.3483 - acc: 0.5634 - val_loss: 1.1566 - val_acc: 0.5836\n",
            "Epoch 12/20\n",
            "35/35 [==============================] - 2s 67ms/step - loss: 4.3186 - acc: 0.5259 - val_loss: 1.3236 - val_acc: 0.4627\n",
            "Epoch 13/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 3.7625 - acc: 0.5795 - val_loss: 1.1779 - val_acc: 0.5536\n",
            "Epoch 14/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 3.5133 - acc: 0.5677 - val_loss: 1.2168 - val_acc: 0.5427\n",
            "Epoch 15/20\n",
            "35/35 [==============================] - 2s 67ms/step - loss: 3.2469 - acc: 0.6098 - val_loss: 1.0765 - val_acc: 0.5455\n",
            "Epoch 16/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 3.0498 - acc: 0.6023 - val_loss: 1.1285 - val_acc: 0.5509\n",
            "Epoch 17/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 2.4660 - acc: 0.6539 - val_loss: 1.4299 - val_acc: 0.4009\n",
            "Epoch 18/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 2.0973 - acc: 0.6391 - val_loss: 1.0379 - val_acc: 0.6291\n",
            "Epoch 19/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 1.9351 - acc: 0.6620 - val_loss: 1.6324 - val_acc: 0.3136\n",
            "Epoch 20/20\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 1.7994 - acc: 0.6677 - val_loss: 1.1052 - val_acc: 0.5400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf7960c610>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = model.predict(x_test)\n",
        "\n",
        "pred_class = []\n",
        "for pred in y:\n",
        "  pred_class.append(np.argmax(pred))"
      ],
      "metadata": {
        "id": "1VDEozVWX8-u"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "F1 = f1_score(y_test, pred_class, average=\"weighted\")"
      ],
      "metadata": {
        "id": "hkelKN8KYFQn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up2DSIHKZn9g",
        "outputId": "2369f598-0fc4-474d-ed06-a1d5b60f5b98"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6273016530945846"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0iMI0FYhaKz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}